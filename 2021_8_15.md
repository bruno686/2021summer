#### 今日任务

------

1.学习李沐的softmax回归

#### 收获

1.交叉熵用来衡量两个概率的区别，将它作为损失

2.L1和L2 loss的区别
$$
l(y,y^{'})=\frac{1}{2}(y-y^{'})^2 \ \ L_2Loss \\ 
l(y,y^{'})=|y-y^{'}|\ \ L_1Loss
$$
3.batch是用来并行处理的，在DataLoader将数据按照batch划分成很多份，每一份数据送入神经网络中进行训练

4.loss在众多数据下是如何更新的，还有optim细节？