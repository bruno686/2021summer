#### 收获

**1.softmax的使用**

```python
import torch
import torch.nn.functional as F
x= torch.Tensor( [ [1,2,3,4],[1,2,3,4],[1,2,3,4]])

y1= F.softmax(x, dim = 0) #对每一列进行softmax
print(y1)

y2 = F.softmax(x,dim =1) #对每一行进行softmax
print(y2)

x1 = torch.Tensor([1,2,3,4])
print(x1)

y3 = F.softmax(x1,dim=0) #一维时使用dim=0，使用dim=1报错
print(y3)
```

**2.torch.arange和range的使用**

```python
>>> y=torch.range(1,6)
>>> y
tensor([1., 2., 3., 4., 5., 6.])
>>> y.dtype
torch.float32

>>> z=torch.arange(1,6)
>>> z
tensor([1, 2, 3, 4, 5])
>>> z.dtype
torch.int64
```

1. `torch.range(start=1, end=6)` 的结果是会包含`end`的，
   而`torch.arange(start=1, end=6)`的结果并不包含`end`。
2. 两者创建的`tensor`的类型也不一样。

**3.每一次传进model里面训练的X的维度是(batch_size,features)**